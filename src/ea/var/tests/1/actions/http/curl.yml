properties:
  parameters:
   - name: agent-curl
     value: null
   - name: debug
     value: false
   - name: curl-body
     value: null
   - name: curl-headers
     value: null
   - name: curl-hosts
     value: http://10.0.0.1
   - name: curl-proxy
     description: http://proxy:8080
     value: null
   - name: curl-method
     value: GET
   - name: curl-options
     value: null
   - name: response-body-json
     description: error -> .*
     value: null
   - name: response-body-text
     description: <title>Extensive.*</title>
     value: null
   - name: response-body-xml
     description: //s:Body -> .*
     value: null
   - name: response-body-xmlns
     description: "s\thttp://www.w3.org/2003/05/soap-envelope\nr\thttp://www.holidaywebservice.com/HolidayService_v2/"
     value: null
   - name: response-code
     value: 200
   - name: response-headers
     description: '[S|s]erver:.*'
     value: null
   - name: response-phrase
     value: null
   - name: response-version
     value: null
   - name: timeout
     value: 3
   - name: timeout-connect
     value: 3
   - name: verbose
     value: true
python: |
    class Curl(Action):
      def definition(self, host):
          agent_support = False
          if input('agent-curl') is not None:
              agent_support = True
              
          self.ADP_CURL = SutAdapters.WEB.Curl(parent=self, name=None, 
                                               debug=input('debug'),
                                               shared=False,
                                               agentSupport=agent_support,
                                               agent=input('agent-curl'),
                                               logEventSent=input('verbose'), 
                                               logEventReceived=input('verbose'))
                                               
          # import python libraries
          import re
          import json
          
          try:
              from jsonpath_ng.ext import parse
          except ImportError:
              self.abort("please to install the jsonpath library")
          try:
              import lxml
              from lxml import etree
          except ImportError:
              self.abort("please to install the lxml library")

          step_details = []

          # prepare headers and ignore commented headers
          req_headers = None
          if input('curl-headers') is not None:
              req_headers = []
              for req_hdr in input('curl-headers').splitlines():
                  if req_hdr.startswith("#"): continue
                  if ":" not in req_hdr:
                      self.abort("request headers malformed (%s)" % req_hdr)
                  req_headers.append(req_hdr)
              req_headers = "\n".join(req_headers)

          # send the request
          body_req = input('curl-body')
          for inp in  inputs() :
              if inp["name"] == "curl-body":
                  if inp["type"] == "json":
                      try:
                          body_req = json.dumps(body_req)
                      except Exception as e:
                          self.abort("invalid json provided for body: %s" % e)
                          body_req = None
                      break

          if input('curl-proxy') is not None:
              self.info("using proxy %s"%input('curl-proxy'))

          self.info("> requesting %s" % host)
          self.ADP_CURL.sendHttp(host=host,
                                 method=input('curl-method'),
                                 headers=req_headers,
                                 body=body_req,
                                 proxy_host=input('curl-proxy'),
                                 timeout_connect=input('timeout-connect'),
                                 timeout_max = input('timeout') ,
                                 more=input('curl-options'))

          # try to match a generic response
          evt = self.ADP_CURL.hasReceivedHttpResponse(timeout=input('timeout'))
          if evt is None:
            self.abort("< no http response received")
          
          # check the http code of the response
          if input('response-code') is not None:
              rsp_code = evt.get("CURL_HTTP_RESPONSE", "code")
              op_regexp = TestOperators.RegEx(needle="%s" % input('response-code'))
              if not op_regexp.seekIn(haystack=rsp_code):
                  msg_error = "- checking http code: KO (%s received, %s expected)" % (rsp_code, input('response-code'))
                  self.abort(msg_error)
              self.info("- checking http code (%s): OK" % input('response-code'))

          # check the http phrase of the response
          if input('response-phrase') is not None:
              rsp_phrase = evt.get("CURL_HTTP_RESPONSE", "phrase")
              op_regexp = TestOperators.RegEx(needle=input('response-phrase'))
              if not op_regexp.seekIn(haystack=rsp_phrase):
                  msg_error = "- checking http phrase: KO (%s received, %s expected)" % (rsp_phrase, input('response-phrase'))
                  self.abort( msg_error )
              self.info( "- checking http phrase (%s): OK" %  input('response-phrase'))

          # check the http version
          if input('response-version') is not None:
              rsp_version = evt.get("CURL_HTTP_RESPONSE", "version")
              op_regexp = TestOperators.RegEx(needle=input('response-version'))
              if not op_regexp.seekIn(haystack=rsp_version):
                  msg_error = "- checking http version: KO (%s received, %s expected)" % (rsp_version, input('response-version'))
                  self.abort( msg_error )
              self.info("- checking http version (%s): OK" % input('response-version'))

          # check headers in response
          if input('response-headers') is not None:
              rsp_headers = evt.get("CURL_HTTP_RESPONSE", "headers")
              for hv in input('response-headers').splitlines():
                  # ignore commented header
                  if hv.startswith("#"): continue
                  if ":" not in hv:
                      self.abort("expected headers in response malformed (%s)" % req_hdr)
                  hdr_found = False
                  for rsp_hdr in rsp_headers.splitlines():
                      # check if the header provided exists on headers of the response
                      if TestOperators.RegEx(needle=hv).seekIn(haystack=rsp_hdr):
                          hdr_found = True
                          self.info("- checking http header (%s): OK " % hv)
                          # capture header value and save it in the cache
                          Cache().capture(data=rsp_hdr, regexp=hv )

                  if not hdr_found:
                      self.abort( "- checking http header (%s): KO " % hv)

          # checking body raw ?
          if input('response-body-text') is not None:
              body_regexp = ".*".join(input('response-body-text').splitlines())
              op_regexp = TestOperators.RegEx(needle=".*%s.*" % body_regexp)
              if not op_regexp.seekIn(haystack=evt.get("CURL_HTTP_RESPONSE", "body")):
                  msg_error = "- checking http body: KO (%s expected)" % (body_regexp)
                  self.abort( msg_error )

              # capture header value and save it in the cache
              Cache().capture(data=evt.get("CURL_HTTP_RESPONSE", "body"), regexp=body_regexp )

              self.info("- checking http body: OK")

          # checking body json ?
          if input('response-body-json') is not None:
              try:
                  body_json = json.loads(evt.get("CURL_HTTP_RESPONSE", "body"))
              except:
                  body_json = None
              if body_json is None: self.abort("- checking http body format: KO (json expected)")
              self.info( "- checking http body format: OK (valid json)"  )

              for line in input('response-body-json').splitlines():
                  if line.startswith("#"): continue

                  if len(re.split(r' -> ', line)) != 2:
                     self.abort("invalid json value=%s, expected <jsonpath> -> <regexp>" % (line) )

                  jpath, jvalue = re.split(r' -> ', line)
                  try:
                      json_values =  [match.value for match in parse(jpath).find(body_json)]
                  except Exception as e:
                      self.error('bad jsonpath (%s) provided ? more details:\n\n %s' % (jpath, str(e)) )
                      json_values = []
                  if not len(json_values):
                      self.abort( "- searching in json response '%s' with the value '%s' : KO" % (jpath, jvalue) )

                  #  search capture regexp
                  capture_detected = re.findall("\(\?P\<.*\>.*\)", jvalue)
                  if capture_detected:
                      cache_key = jvalue.split("(?P<")[1].split(">.*)")[0]
                      if len(json_values) == 1:
                          Cache().capture(data="%s" % json_values[0], regexp=jvalue)
                      else:
                          Cache().set(name=cache_key, data=json_values, flag=False)
                      self.info( "- searching in json response and capture value of '%s'" % (jpath) )

                  else:
                      values_detected = False
                      for jv in json_values:
                          if TestOperators.RegEx(needle=jvalue).seekIn(haystack="%s" % jv):
                              values_detected = True

                      if not values_detected:
                          self.abort( "- searching in json response '%s' with the value '%s' : KO" % (jpath, jvalue) )
                      else:
                          self.info( "- searching in json response '%s' with the value '%s' : OK" % (jpath, jvalue)  )

          # checking body xml ?
          if input('response-body-xml') is not None:
              body_xml  = evt.get("CURL_HTTP_RESPONSE", "body")
              valid = True
              try:
                  etree.XML( bytes(body_xml, "utf8") )
              except Exception as e:
                  self.error( "invalid xml %s" % e)
                  valid = False
              if not valid:
                  self.abort("- checking http body format: KO (xml expected)")
              self.info( "- checking http body format: OK (valid xml)"  )

              ns = {}
              if input('response-body-xmlns') is not None:
                  for line in input('response-body-xmlns').splitlines():
                      if len(re.split(r' -> ', line)) != 2:
                          self.abort("bad namespaces provided value=%s, expected <name> -> <namespace>" % (line) )
                      ns_name, namespace = re.split(r' -> ', line)
                      ns[ns_name] = namespace

              for line in input('response-body-xml').splitlines():
                  if line.startswith("#"): continue

                  if len(re.split(r' -> ', line)) != 2:
                      self.abort("bad xml body provided value=%s, expected <xpath> -> <regexp>" % (line) )
                  xpath, xvalue = re.split(r'\t+', line)

                  # search data with xpath in xml
                  xml_values = []
                  try:
                      rootXML = etree.XML( bytes(body_xml, "utf8") )
                      findXML= etree.XPath(xpath, namespaces=ns)
                      retXML =  findXML(rootXML)

                      for el in retXML:
                          if isinstance(el, etree._Element ):
                              xml_values.append( "%s" % el.text)
                          else:
                              xml_values.append( "%s" % el )
                  except Exception as e:
                      self.error('unable to get all xml values: %s' % str(e) )
                      xml_values = []
                  if not len(xml_values):
                      self.abort( "- searching '%s' with the value '%s' : KO" % (xpath, xvalue) )

                  #  search capture regexp
                  capture_detected = re.findall("\(\?P\<.*\>.*\)", xvalue)
                  if capture_detected:
                      cache_key = xvalue.split("(?P<")[1].split(">.*)")[0]
                      if len(xml_values) == 1:
                          Cache().capture(data="%s" % xml_values[0], regexp=xvalue)
                      else:
                          Cache().set(name=cache_key, data=xml_values, flag=False)
                      self.info( "- searching and capture value of '%s'" % (xpath) )

                  else:
                      values_detected = False
                      for jv in xml_values:
                          if TestOperators.RegEx(needle=xvalue).seekIn(haystack="%s" % jv):
                              values_detected = True
                      if not values_detected:
                          self.abort( "- searching '%s' with the value '%s' : KO" % (xpath, xvalue) )
                      else:
                          self.info( "- searching '%s' with the value '%s' : OK" % (xpath, xvalue) )

    hosts = input('curl-hosts')
    if hosts is None: AbortTestSuite(reason="no hosts provided")
    if not isinstance(hosts, list): hosts = [ input('curl-hosts') ]

    for host in hosts:
      Curl().execute(host=host)
